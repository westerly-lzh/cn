---
layout: post
title: R语言统计分析学习系列之多元统计分析
categories:
- statistic
- 统计
tags:
- 多元分析

---

这里仍然是介绍在R中怎样做多元分析，其中包括判别分析（Discriminat Analysis），聚类分析，主成分分析，因子分析，对应分析，典型相关分析。主要参考了多元统计分析及R语言建模(王斌会，第二版)，R语言与统计分析(汤银才)及R语言实践(Rotert I. Kabacoff)。本人是学管理学出身，对一些比较深奥的统计建模过程不是很了解，所以这里只是讲述如何使用R来做上述的分析任务，具体的推理过程就略过了。原本想再这上面采用mathjax的，但是jekyll渲染后的效果不是很好，就先作罢了。
#####1 判别分析(Discriminat Analysis)
判别分析是用于判别样本具体所属类型的一种统计分析方法，这里的前提是总体的分类已经确定。这里主要介绍Fisher判别和Bayes判别。Fisher判别属于确定性判别，这里介绍其中的线性判别和距离判别；而Bayes判别属于概率判别。

######1.1 线性判别
线性判别采用线性判别函数，这里建立的线性判别函数为Y = a_1 X_1 + a_2 X_2 + … + a_n X_n ,使得该函数可以根据样本的不同指标(X_i)来区分样本。在该线性判别函数中重要的是求得判别函数的系数，使得在同组内部的变异尽可能的小，而不同组之间的变异尽可能的大，这里的系数也就是Fisher判别方法中的投影方向。在R中我们可以使用MASS包中的lda函数来进行线性判别分析。取得判别结果后，我们可以使用样品的真是分类和预测分类进行列链表分析，在使用lda时，其结果中线性判别系数(Coefficients of linear discriminants)一项，可能出现多组，而(Proportion trace)一项则指明了每一组线性判别系数在对样本进行分组判别时的贡献大小。

``` 
data(iris) 
ld <- lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,data=iris)
ld ##查看判别效果
z <- predict(ld)
cbind(iris$Species,z$class) ##对比实际类型和判别分类
tab <- table(iris$Species,z$class) ##列链表显示判别结果
tab
diag(prop.table.table(tab,1))
```
在做判别分析中，要始终牢记样本集中样本的指标是否等方差，及协方差阵是否相同；不同的方差和协方差，在使用lda时，如果没有指明，其判别结果会有不同。

######1.2 距离判别

距离判别中重要的是选择适当的距离函数，在下面的聚类分析中会再次提到距离的定义，所采用的距离定义不同，会导致不同的判别和聚类结果。在判别分析中比较常用的距离是马氏距离，但具体采用何种距离定义方式要根据实际的问题来决定。这里根据距离定义，会产生距离函数W(x)，对于k个总体,某个样本到各个总体的距离最小为 W_i = min(W(x)),则所要判定的样本可归入第i类别。在R中可以使用MASS包中的discrim.dist函数进行判别，默认情况下，该函数假定样本的方差不等。在王斌会那本书上，有一个mvstats包，提供了有供距离判别的函数，但没有找到该包，所以这里就作吧了。

######1.3 Bayes判别
Bayes判别相比较前面的线性判别和距离判别，考虑了各个总体出现的概率(即先验概率)和错判的损失函数，综合考虑这两个条件，则使得损失函数最小化，可以作为判别分类的标准.在R中，我们依然可以使用lda函数进行Bayes判别，与之前说的线性判别不同的是，我们只要指定先验概率参数(prior)，使用lda进行Bayes判别时，情况变得有些复杂，具体可以参见lda的使用帮助。

以下观点来自多元统计分析与R语言建模(王斌会,第二版):
>判别分析中，距离判别和Fisher判别(线性判别)对判别变量的分布类型没有要求，两者只要求各类总体的二阶矩存在，而Bayes判别则要求知道变量的分布类型；当仅有两个总体时，若他们的协方差矩阵相同，则距离判别和Fisher判别等价，当判别变量服从正态分布时，他们还和Bayes判别等价，而当两类的协方差矩阵不同时，Fisher判别使用的是他们的额合并协方差矩阵，距离判别也与Bayes判别不同

####2 聚类分析


<!--

线性判别采用线性判别函数 $$Y = {a_1}{X_1} + {a_2}{X_2} + \cdots +{a_n}{X_n}$$,使得该函数能够根据$X_i$ 的值区分各个样品。在该线性判别函数中，重要的是需要根据已有样本计算出的系数向量$\overrightarrow{a}$能使得各个类别之间的变异尽量大，而类内的变异尽量小。这里按照上述的要求如何求得$\overrightarrow{a}$就不做表述，但在有$Y = \mathbf{aX}$后,我们可以把各个类别的样品指标均值带入$Y_i = \overrightarrow{a}\overline{X_i}$, 求得$${Y_1},{Y_2},{\cdots},{Y_n}$$，其中$Y_1 < Y_2  < \cdots < Y_n$,则新样本$X$指标带入指标函数得到$Y$后，只需要先判断$Y$在 $[Y_i , Y_{i+1}]$,然后比较$Y$与$\frac{Y_i + Y_{i+1}}{2}$的大小，当$Y > \frac{Y_i + Y_ {i+1}}{2}$时，$X$属于$Y_{i+1}$类别，反之属于${Y_i}$类别

-->